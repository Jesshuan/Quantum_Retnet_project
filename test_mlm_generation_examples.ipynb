{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from retnet.modeling_retnet import RetNetForCausalLM\n",
    "from retnet.configuration_retnet import load_config_from_json\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RetNetForCausalLM.from_pretrained(\"./model_store/model_small_mlm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "config = load_config_from_json('configs/retnet-base/config.json')\n",
    "model = RetNetForCausalLM(config)\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.model_max_length = 4096\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "#tokenizer.unk_token = tokenizer.eos_token\n",
    "#tokenizer.bos_token = tokenizer.eos_token\n",
    "\n",
    "context_inputs = tokenizer(\"<|endoftext|> It was very interesting but . Okay, men .\", return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[50256,   632,   373,   845,  3499,   475,   764, 16805,    11,  1450,\n",
       "           764]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel forward\n",
    "# our custom generate function\n",
    "generated = model.custom_generate(context_inputs['input_ids'], parallel_compute_prompt=True, max_new_tokens=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = model.generate(**context_inputs, max_new_tokens=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|endoftext|> It was very interesting but. Okay, men. ian and i were in the same room. ianna. ian, who had been in the middle of the night, and the next morning, the only one of the other men had been in the middle of the house. ianna. ian s house was a few feet away from the middle of the house. ian s house. ian had been a few years ago. ianna saturday morning. ian had been a few years ago. ive, and he d never had a good time to be. ian had been a good idea. ianna saturday night. ian s house. ian was n t a good thing to do. ian s. ianna had been in the first place. ianna had n t had a family. ian s. ian s house, and he was n t a good idea. ianna had been in the last two days. ianna.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "context_sentence = [\"When she look the bay, she thinks \",\\\n",
    "                    \"Of course, he didn't go to the supermarket because \",\\\n",
    "                    \"A best thing i've never say to anywone is \",\\\n",
    "                     \"And the wind \",\\\n",
    "                    \"On the other side, a very large tree was \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Context --- \n",
      " When she look the bay, she thinks \n",
      "---- Response ---- \n",
      " ['When she look the bay, she thinks ive been doing this. ive been doing this. ive been doing this before. ive']\n",
      "----\n",
      "--- Context --- \n",
      " Of course, he didn't go to the supermarket because \n",
      "---- Response ---- \n",
      " [\"Of course, he didn't go to the supermarket because ian is a good man. ian. ian. ian, and i m not sure\"]\n",
      "----\n",
      "--- Context --- \n",
      " A best thing i've never say to anywone is \n",
      "---- Response ---- \n",
      " [\"A best thing i've never say to anywone is ive been in a few days. ive been in a while. ian is n t a\"]\n",
      "----\n",
      "--- Context --- \n",
      " And the wind \n",
      "---- Response ---- \n",
      " ['And the wind iced the air, and the air was a little too small. ian. ian had been']\n",
      "----\n",
      "--- Context --- \n",
      " On the other side, a very large tree was \n",
      "---- Response ---- \n",
      " ['On the other side, a very large tree was ian. ian. ian. ian, who was a man who had been a man']\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for sentence in context_sentence:\n",
    "    print(f\"--- Context --- \\n {sentence}\")\n",
    "    context_inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    generated = model.generate(context_inputs['input_ids'], max_new_tokens=20)\n",
    "    print(f\"---- Response ---- \\n {tokenizer.batch_decode(generated)}\")\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retnet_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
