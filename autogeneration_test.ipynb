{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from retnet.modeling_retnet import RetNetForCausalLM\n",
    "from retnet.configuration_retnet import load_config_from_json\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/shakespeare.txt\", \"rb\") as f:\n",
    "    text = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = load_config_from_json('configs/retnet-base/config.json')\n",
    "model = RetNetForCausalLM(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.model_max_length = 1000000\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "context_inputs = tokenizer(\"I have a request for you, my sire.\", return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel forward\n",
    "# our custom generate function\n",
    "generated = model.custom_generate(context_inputs['input_ids'], parallel_compute_prompt=True, max_new_tokens=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = model.generate(**context_inputs, max_new_tokens=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   40,   423,   257,  2581,   329,   345,    11,   616,   264,   557,\n",
       "            13, 37243, 15841, 46194, 40791, 45726, 42678, 24962, 14478, 47854,\n",
       "         35026, 19192, 20486, 35408, 34015, 33585,  7729, 43324,  7525, 31710,\n",
       "         26604]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I have a request for you, my sire. Chern Mak Roku.? Bahamas CapitalismurstPass Thro videot Mosul tajected moms mitigation instructions nervously primarilyBostonÂ¶']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tokenizer.encode(text, return_tensors='pt', return_attention_mask=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "n = int(0.9 * len(data))\n",
    "data_train = data[:n]\n",
    "data_val = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "BLOCK_SIZE = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading function to get input (x) and target (y) batches\n",
    "def get_batch(split_type, batch_size, data_train, data_val, block_size):\n",
    "    data = data_train if split_type == 'train' else data_val\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_test, y_train_test = get_batch(\"train\", BATCH_SIZE, data_train, data_val, BLOCK_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_test = model(x_train_test)[\"logits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RetNetCausalLMOutputWithPast(loss=None, logits=tensor([[[ 0.5378,  0.4868, -1.5332,  ...,  0.3570, -0.1741, -0.4460],\n",
       "         [ 0.5664,  0.4663, -1.5862,  ...,  0.4134, -0.1759, -0.2898],\n",
       "         [ 1.0328, -0.3031,  2.1131,  ..., -0.6309, -0.1988, -0.5183],\n",
       "         ...,\n",
       "         [-0.6413, -0.2282, -0.8098,  ...,  0.0620,  0.0032,  1.5376],\n",
       "         [-0.2352, -0.5176, -2.5079,  ..., -0.3055,  1.5851,  1.1990],\n",
       "         [-0.3700,  1.0973,  0.2156,  ..., -1.1637, -2.1866,  0.0649]]],\n",
       "       grad_fn=<UnsafeViewBackward0>), past_key_values=(None, None, None, None, None, None), hidden_states=None, retentions=None, attentions=None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_train_test, y_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'past_key_values'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_iter = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = load_config_from_json('configs/retnet-base/config.json')\n",
    "model = RetNetForCausalLM(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5397,  0.4509, -1.5759,  ...,  0.3701, -0.1832, -0.3811],\n",
       "         [ 0.5523,  0.4654, -1.5932,  ...,  0.3871, -0.1746, -0.3381],\n",
       "         [ 1.0607, -0.2741,  2.1151,  ..., -0.6813, -0.2821, -0.4561],\n",
       "         ...,\n",
       "         [-0.7678, -0.1694, -0.9424,  ...,  0.1731,  0.0495,  1.6391],\n",
       "         [-0.1331, -0.4586, -2.6028,  ..., -0.1229,  1.5787,  1.1152],\n",
       "         [-0.2104,  1.1515,  0.1176,  ..., -1.2531, -2.2347,  0.1857]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10051400])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_test.contiguous().view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(NB_EPOCHS):\n",
    "    optimizer.zero_grad()\n",
    "    X, Y = get_batch(\"train\", BATCH_SIZE, data_train, data_val, BLOCK_SIZE)\n",
    "    output = model(X)['logits']\n",
    "    print(output)\n",
    "    loss = criterion(output.contiguous().view(-1), Y[:, 1:].contiguous().view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retnet_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
