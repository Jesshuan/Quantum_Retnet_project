{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jdine/miniconda3/envs/retnet_test/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import pickle\n",
    "\n",
    "from retention import SimpleRetention, MultiScaleRetention\n",
    "from retnet import RetNet\n",
    "\n",
    "\n",
    "# Import the 'einops' library\n",
    "import einops\n",
    "from einops import rearrange, reduce, repeat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-26 12:30:14--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8002::154, 2606:50c0:8001::154, 2606:50c0:8003::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8002::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1,1M) [text/plain]\n",
      "Saving to: ‘input.txt’\n",
      "\n",
      "input.txt           100%[===================>]   1,06M  1,37MB/s    in 0,8s    \n",
      "\n",
      "2024-02-26 12:30:15 (1,37 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
      "\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Download a text file from a GitHub repository\n",
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "# Open the downloaded file for reading with UTF-8 encoding\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "len(text)\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save raw text :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./../data/shakespeare.txt\", \"wb\") as f:\n",
    "    pickle.dump(text, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-load :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./../data/shakespeare.txt\", \"rb\") as f:\n",
    "    text = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to create a decay matrix with a specified dimension and gamma values\n",
    "def get_decay_matrix(dim, gamma):\n",
    "    d = torch.ones(dim)\n",
    "    d = torch.tril(d)\n",
    "    for index, head in enumerate(d):\n",
    "        g = gamma[index]\n",
    "        for idx, x in enumerate(torch.tril(head)):\n",
    "            for idy, y in enumerate(x):\n",
    "                if idx >= idy:\n",
    "                    head[idx][idy] = g ** (idx-idy)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data loading function to get input (x) and target (y) batches\n",
    "def get_batch(split, batch_size, train_data, val_data, block_size):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 16\n",
    "seq_len = 20\n",
    "max_iters = 100\n",
    "eval_interval = 10\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 20\n",
    "n_head = 4\n",
    "n_layer = 2\n",
    "dropout = 0.0\n",
    "n_embed = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6151/1214614951.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  xb_test = torch.tensor(torch.zeros([3, seq_len]), dtype=torch.long)\n",
      "/tmp/ipykernel_6151/1214614951.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  yb_test = torch.tensor(torch.zeros([3, seq_len]), dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "xb_test = torch.tensor(torch.zeros([3, seq_len]), dtype=torch.long)\n",
    "yb_test = torch.tensor(torch.zeros([3, seq_len]), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigRetNet(nn.Module):\n",
    "    def __init__(self, n_layer, n_embed, ffn_size, n_head, vocab_size, seq_len):\n",
    "        super().__init__()\n",
    "\n",
    "        self.retnet = RetNet(layers=n_layer, hidden_dim=n_embed, ffn_size=ffn_size, heads=n_head)\n",
    "\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_embedding_table = nn.Embedding(seq_len, n_embed)\n",
    "        self.blocks = nn.Sequential(*[RetNet(layers=n_layer, hidden_dim=n_embed, ffn_size=ffn_size, heads=n_head) for _ in range(n_layer)])\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        token_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T))\n",
    "        x = token_emb + pos_emb\n",
    "        x = self.blocks(x)\n",
    "        logits = self.lm_head(x)\n",
    "        if targets == None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "    \n",
    "\n",
    "    def forward_recurrent(self, idx):\n",
    "        pass\n",
    "    \n",
    "    \"\"\"def train_parallelize(self, idx, targets):\n",
    "        logits = self(idx)\n",
    "        B, T, C = logits.shape\n",
    "        logits = logits.view(B*T, C)\n",
    "        targets = targets.view(B*T)\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RetNet model\n",
    "model = BigRetNet(n_layer, n_embed, 2*n_embed, n_head, vocab_size, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, loss = model(xb_test, yb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 65])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3119, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create a sorted list of unique characters in the text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create character-to-index and index-to-character mappings\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}\n",
    "# Functions to encode and decode text\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: \"\".join([itos[x] for x in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[46, 47, 1, 58, 46, 43, 56, 43]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "encode(\"hi there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi there'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode([46, 47, 1, 58, 46, 43, 56, 43])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the text to a PyTorch tensor of character indices\n",
    "data = torch.tensor(encode(text), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into training and validation sets\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to estimate loss on train and validation sets\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split, batch_size=batch_size, train_data=train_data, val_data=val_data, block_size=seq_len)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "xb, yb = get_batch('train', batch_size=batch_size, train_data=train_data, val_data=val_data, block_size=seq_len)\n",
    "\n",
    "\n",
    "# Forward pass and loss calculation\n",
    "logits, loss = model(xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size * seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([320, 65])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.6459, val loss 4.6237\n",
      "step 99: train loss 3.7512, val loss 3.7784\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "for iter in range(max_iters):\n",
    "    # Every once in a while, evaluate the loss on train and val sets\n",
    "    if iter % 100 == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "\n",
    "    # Sample a batch of data\n",
    "    xb, yb = get_batch('train', batch_size=batch_size, train_data=train_data, val_data=val_data, block_size=seq_len)\n",
    "\n",
    "\n",
    "    # Forward pass, loss calculation, backpropagation, and optimization\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STOP - TO DO NEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thp; as mth dofowhiicaye dw RDUo,\n",
      "Se thixghad pe tellldeaseadm f gad,\n",
      "OWINANTh o, w Le E aps hpor ale,\n",
      "An bl Bou by slor!\n",
      "TIThandellatr gonghed ty Myoll cat tomillitu wiswingoblthithusferd win 'LDIUMY\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a context for text generation\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "# Generate text using the model\n",
    "print(decode(model.generate(context, max_new_tokes=200)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A\n",
      "L torn d s y, whr, rdend t Thaly, athaturOFr,\n",
      "ICINRINGENatora lbst:\n",
      "Hir ydorand.\n",
      "The cheedustocngurgothiserisdr ttortrcoryof sped s mswithary ithoknwe l\n",
      "Borifry lyolo foou;\n",
      "ICHUCUWA beenomz,\n",
      "Tin ies\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create another context for text generation\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "# Generate more text using the model\n",
    "print(decode(model.generate(context, max_new_tokes=200)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.6.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2023.12.25-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests>=2.26.0 (from tiktoken)\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.26.0->tiktoken)\n",
      "  Downloading charset_normalizer-3.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.26.0->tiktoken)\n",
      "  Downloading idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.26.0->tiktoken)\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.26.0->tiktoken)\n",
      "  Downloading certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Downloading tiktoken-0.6.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.12.25-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (789 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m789.1/789.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.6-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: urllib3, regex, idna, charset-normalizer, certifi, requests, tiktoken\n",
      "Successfully installed certifi-2024.2.2 charset-normalizer-3.3.2 idna-3.6 regex-2023.12.25 requests-2.31.0 tiktoken-0.6.0 urllib3-2.2.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Install the 'tiktoken' library\n",
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import the 'tiktoken' library\n",
    "import tiktoken\n",
    "# Get the encoding for a specific model\n",
    "enc = tiktoken.get_encoding(\"r50k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Encoding 'r50k_base'>"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assert that encoding and decoding work correctly\n",
    "assert enc.decode(enc.encode(\"hello world\")) == \"hello world\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31373, 995]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.encode(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# To get the tokeniser corresponding to a specific model in the OpenAI API:\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Assert that encoding and decoding work correctly for the new model\n",
    "assert enc.decode(enc.encode(\"hello world\")) == \"hello world\" \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31373, 995]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Encode \"hello world\" using the tokeniser\n",
    "enc.encode(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sub = text[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1393"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Count the number of tokens in the text\n",
    "text_tokens = enc.encode(text_sub)\n",
    "len(text_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5962,\n",
       " 22307,\n",
       " 25,\n",
       " 198,\n",
       " 8421,\n",
       " 356,\n",
       " 5120,\n",
       " 597,\n",
       " 2252,\n",
       " 11,\n",
       " 3285,\n",
       " 502,\n",
       " 2740,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 3237,\n",
       " 25,\n",
       " 198,\n",
       " 5248,\n",
       " 461,\n",
       " 11,\n",
       " 2740,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 5962,\n",
       " 22307,\n",
       " 25,\n",
       " 198,\n",
       " 1639,\n",
       " 389,\n",
       " 477,\n",
       " 12939,\n",
       " 2138,\n",
       " 284,\n",
       " 4656,\n",
       " 621,\n",
       " 284,\n",
       " 1145,\n",
       " 680,\n",
       " 30,\n",
       " 198,\n",
       " 198,\n",
       " 3237,\n",
       " 25,\n",
       " 198,\n",
       " 4965,\n",
       " 5634,\n",
       " 13,\n",
       " 12939,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 5962,\n",
       " 22307,\n",
       " 25,\n",
       " 198,\n",
       " 5962,\n",
       " 11,\n",
       " 345,\n",
       " 760,\n",
       " 327,\n",
       " 1872,\n",
       " 385,\n",
       " 1526,\n",
       " 28599,\n",
       " 318,\n",
       " 4039,\n",
       " 4472,\n",
       " 284,\n",
       " 262,\n",
       " 661,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 3237,\n",
       " 25,\n",
       " 198,\n",
       " 1135,\n",
       " 760,\n",
       " 470,\n",
       " 11,\n",
       " 356,\n",
       " 760,\n",
       " 470,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 5962,\n",
       " 22307,\n",
       " 25,\n",
       " 198,\n",
       " 5756,\n",
       " 514,\n",
       " 1494,\n",
       " 683,\n",
       " 11,\n",
       " 290,\n",
       " 356,\n",
       " 1183,\n",
       " 423,\n",
       " 11676,\n",
       " 379,\n",
       " 674,\n",
       " 898,\n",
       " 2756,\n",
       " 13,\n",
       " 198,\n",
       " 3792,\n",
       " 470,\n",
       " 257,\n",
       " 15593,\n",
       " 30,\n",
       " 198,\n",
       " 198,\n",
       " 3237,\n",
       " 25,\n",
       " 198,\n",
       " 2949,\n",
       " 517,\n",
       " 3375,\n",
       " 319,\n",
       " 470,\n",
       " 26,\n",
       " 1309,\n",
       " 340,\n",
       " 307,\n",
       " 1760,\n",
       " 25,\n",
       " 1497,\n",
       " 11,\n",
       " 1497,\n",
       " 0,\n",
       " 198,\n",
       " 198,\n",
       " 12211,\n",
       " 22307,\n",
       " 25,\n",
       " 198,\n",
       " 3198,\n",
       " 1573,\n",
       " 11,\n",
       " 922,\n",
       " 4290,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 5962,\n",
       " 22307,\n",
       " 25,\n",
       " 198,\n",
       " 1135,\n",
       " 389,\n",
       " 17830,\n",
       " 3595,\n",
       " 4290,\n",
       " 11,\n",
       " 262,\n",
       " 1458,\n",
       " 1173,\n",
       " 1547,\n",
       " 922,\n",
       " 13,\n",
       " 198,\n",
       " 2061,\n",
       " 4934,\n",
       " 969,\n",
       " 5036,\n",
       " 896,\n",
       " 319,\n",
       " 561,\n",
       " 26958,\n",
       " 514,\n",
       " 25,\n",
       " 611,\n",
       " 484,\n",
       " 198,\n",
       " 19188,\n",
       " 7800,\n",
       " 514,\n",
       " 475,\n",
       " 262,\n",
       " 48713,\n",
       " 414,\n",
       " 11,\n",
       " 981,\n",
       " 340,\n",
       " 547,\n",
       " 198,\n",
       " 1929,\n",
       " 4316,\n",
       " 462,\n",
       " 11,\n",
       " 356,\n",
       " 1244,\n",
       " 4724,\n",
       " 484,\n",
       " 22598,\n",
       " 514,\n",
       " 31533,\n",
       " 306,\n",
       " 26,\n",
       " 198,\n",
       " 4360,\n",
       " 484,\n",
       " 892,\n",
       " 356,\n",
       " 389,\n",
       " 1165,\n",
       " 13674,\n",
       " 25,\n",
       " 262,\n",
       " 10904,\n",
       " 1108,\n",
       " 326,\n",
       " 198,\n",
       " 2001,\n",
       " 42267,\n",
       " 514,\n",
       " 11,\n",
       " 262,\n",
       " 2134,\n",
       " 286,\n",
       " 674,\n",
       " 24672,\n",
       " 11,\n",
       " 318,\n",
       " 355,\n",
       " 281,\n",
       " 198,\n",
       " 24807,\n",
       " 284,\n",
       " 1948,\n",
       " 786,\n",
       " 511,\n",
       " 20038,\n",
       " 26,\n",
       " 674,\n",
       " 198,\n",
       " 82,\n",
       " 13712,\n",
       " 590,\n",
       " 318,\n",
       " 257,\n",
       " 4461,\n",
       " 284,\n",
       " 606,\n",
       " 3914,\n",
       " 514,\n",
       " 15827,\n",
       " 428,\n",
       " 351,\n",
       " 198,\n",
       " 454,\n",
       " 279,\n",
       " 7938,\n",
       " 11,\n",
       " 304,\n",
       " 260,\n",
       " 356,\n",
       " 1716,\n",
       " 374,\n",
       " 1124,\n",
       " 25,\n",
       " 329,\n",
       " 262,\n",
       " 11858,\n",
       " 760,\n",
       " 314,\n",
       " 198,\n",
       " 47350,\n",
       " 428,\n",
       " 287,\n",
       " 16460,\n",
       " 329,\n",
       " 8509,\n",
       " 11,\n",
       " 407,\n",
       " 287,\n",
       " 24613,\n",
       " 329,\n",
       " 15827,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 12211,\n",
       " 22307,\n",
       " 25,\n",
       " 198,\n",
       " 17353,\n",
       " 345,\n",
       " 5120,\n",
       " 2592,\n",
       " 1028,\n",
       " 327,\n",
       " 1872,\n",
       " 385,\n",
       " 1526,\n",
       " 28599,\n",
       " 30,\n",
       " 198,\n",
       " 198,\n",
       " 3237,\n",
       " 25,\n",
       " 198,\n",
       " 39276,\n",
       " 683,\n",
       " 717,\n",
       " 25,\n",
       " 339,\n",
       " 338,\n",
       " 257,\n",
       " 845,\n",
       " 3290,\n",
       " 284,\n",
       " 262,\n",
       " 2219,\n",
       " 6017,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 12211,\n",
       " 22307,\n",
       " 25,\n",
       " 198,\n",
       " 19626,\n",
       " 345,\n",
       " 644,\n",
       " 2594,\n",
       " 339,\n",
       " 468,\n",
       " 1760,\n",
       " 329,\n",
       " 465,\n",
       " 1499,\n",
       " 30,\n",
       " 198,\n",
       " 198,\n",
       " 5962,\n",
       " 22307,\n",
       " 25,\n",
       " 198,\n",
       " 16371,\n",
       " 880,\n",
       " 26,\n",
       " 290,\n",
       " 714,\n",
       " 307,\n",
       " 2695,\n",
       " 284,\n",
       " 1577,\n",
       " 683,\n",
       " 922,\n",
       " 198,\n",
       " 13116,\n",
       " 6285,\n",
       " 11,\n",
       " 475,\n",
       " 326,\n",
       " 339,\n",
       " 13831,\n",
       " 2241,\n",
       " 351,\n",
       " 852,\n",
       " 6613,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 12211,\n",
       " 22307,\n",
       " 25,\n",
       " 198,\n",
       " 45,\n",
       " 323,\n",
       " 11,\n",
       " 475,\n",
       " 2740,\n",
       " 407,\n",
       " 17412,\n",
       " 306,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 5962,\n",
       " 22307,\n",
       " 25,\n",
       " 198,\n",
       " 40,\n",
       " 910,\n",
       " 12722,\n",
       " 345,\n",
       " 11,\n",
       " 644,\n",
       " 339,\n",
       " 22027,\n",
       " 1760,\n",
       " 20524,\n",
       " 11,\n",
       " 339,\n",
       " 750,\n",
       " 198,\n",
       " 270,\n",
       " 284,\n",
       " 326,\n",
       " 886,\n",
       " 25,\n",
       " 996,\n",
       " 2705,\n",
       " 12,\n",
       " 5936,\n",
       " 979,\n",
       " 5864,\n",
       " 1450,\n",
       " 460,\n",
       " 307,\n",
       " 198,\n",
       " 11299,\n",
       " 284,\n",
       " 910,\n",
       " 340,\n",
       " 373,\n",
       " 329,\n",
       " 465,\n",
       " 1499,\n",
       " 339,\n",
       " 750,\n",
       " 340,\n",
       " 284,\n",
       " 198,\n",
       " 29688,\n",
       " 465,\n",
       " 2802,\n",
       " 290,\n",
       " 284,\n",
       " 307,\n",
       " 11476,\n",
       " 6613,\n",
       " 26,\n",
       " 543,\n",
       " 339,\n",
       " 198,\n",
       " 271,\n",
       " 11,\n",
       " 772,\n",
       " 10597,\n",
       " 262,\n",
       " 20334,\n",
       " 286,\n",
       " 465,\n",
       " 14675,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 12211,\n",
       " 22307,\n",
       " 25,\n",
       " 198,\n",
       " 2061,\n",
       " 339,\n",
       " 2314,\n",
       " 1037,\n",
       " 287,\n",
       " 465,\n",
       " 3450,\n",
       " 11,\n",
       " 345,\n",
       " 1848,\n",
       " 257,\n",
       " 198,\n",
       " 28281,\n",
       " 287,\n",
       " 683,\n",
       " 13,\n",
       " 921,\n",
       " 1276,\n",
       " 287,\n",
       " 645,\n",
       " 835,\n",
       " 910,\n",
       " 339,\n",
       " 318,\n",
       " 25746,\n",
       " 83,\n",
       " 516,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 5962,\n",
       " 22307,\n",
       " 25,\n",
       " 198,\n",
       " 1532,\n",
       " 314,\n",
       " 1276,\n",
       " 407,\n",
       " 11,\n",
       " 314,\n",
       " 761,\n",
       " 407,\n",
       " 307,\n",
       " 39497,\n",
       " 286,\n",
       " 14227,\n",
       " 26,\n",
       " 198,\n",
       " 258,\n",
       " 22027,\n",
       " 31025,\n",
       " 11,\n",
       " 351,\n",
       " 18201,\n",
       " 11,\n",
       " 284,\n",
       " 15867,\n",
       " 287,\n",
       " 29693,\n",
       " 13,\n",
       " 198,\n",
       " 2061,\n",
       " 34757,\n",
       " 389,\n",
       " 777,\n",
       " 30,\n",
       " 383,\n",
       " 584,\n",
       " 1735,\n",
       " 267,\n",
       " 6,\n",
       " 262,\n",
       " 1748,\n",
       " 198,\n",
       " 271,\n",
       " 17450,\n",
       " 25,\n",
       " 1521,\n",
       " 2652,\n",
       " 356,\n",
       " 778,\n",
       " 803,\n",
       " 994,\n",
       " 30,\n",
       " 284,\n",
       " 262,\n",
       " 13241,\n",
       " 0,\n",
       " 198,\n",
       " 198,\n",
       " 3237,\n",
       " 25,\n",
       " 198,\n",
       " 16773,\n",
       " 11,\n",
       " 1282,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 5962,\n",
       " 22307,\n",
       " 25,\n",
       " 198,\n",
       " 18380,\n",
       " 0,\n",
       " 508,\n",
       " 2058,\n",
       " 994,\n",
       " 30,\n",
       " 198,\n",
       " 198,\n",
       " 12211,\n",
       " 22307,\n",
       " 25,\n",
       " 198,\n",
       " 54,\n",
       " 18906,\n",
       " 6065,\n",
       " 268,\n",
       " 3754,\n",
       " 2449,\n",
       " 14602,\n",
       " 64,\n",
       " 26,\n",
       " 530,\n",
       " 326,\n",
       " 22027,\n",
       " 1464,\n",
       " 6151,\n",
       " 198,\n",
       " 1169,\n",
       " 661,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 5962,\n",
       " 22307,\n",
       " 25,\n",
       " 198,\n",
       " 1544,\n",
       " 338,\n",
       " 530,\n",
       " 5508,\n",
       " 1576,\n",
       " 25,\n",
       " 561,\n",
       " 477,\n",
       " 262,\n",
       " 1334,\n",
       " 547,\n",
       " 523,\n",
       " 0,\n",
       " 198,\n",
       " 198,\n",
       " 49275,\n",
       " 1677,\n",
       " 40,\n",
       " 2937,\n",
       " 25,\n",
       " 198,\n",
       " 2061,\n",
       " 670,\n",
       " 338,\n",
       " 11,\n",
       " 616,\n",
       " 1499,\n",
       " 3653,\n",
       " 11,\n",
       " 287,\n",
       " 1021,\n",
       " 30,\n",
       " 810,\n",
       " 467,\n",
       " 345,\n",
       " 198,\n",
       " 3152,\n",
       " 19553,\n",
       " 290,\n",
       " 9784,\n",
       " 30,\n",
       " 383,\n",
       " 2300,\n",
       " 30,\n",
       " 2740,\n",
       " 11,\n",
       " 314,\n",
       " 12472,\n",
       " 345,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 5962,\n",
       " 22307,\n",
       " 25,\n",
       " 198,\n",
       " 5122,\n",
       " 1597,\n",
       " 318,\n",
       " 407,\n",
       " 6439,\n",
       " 284,\n",
       " 262,\n",
       " 34548,\n",
       " 26,\n",
       " 484,\n",
       " 423,\n",
       " 198,\n",
       " 18108,\n",
       " 16882,\n",
       " 1359,\n",
       " 428,\n",
       " 46327,\n",
       " 644,\n",
       " 356,\n",
       " 14765,\n",
       " 284,\n",
       " 466,\n",
       " 11,\n",
       " 198,\n",
       " 4758,\n",
       " 783,\n",
       " 356,\n",
       " 1183,\n",
       " 905,\n",
       " 705,\n",
       " 368,\n",
       " 287,\n",
       " 23777,\n",
       " 13,\n",
       " 1119,\n",
       " 910,\n",
       " 3595,\n",
       " 198,\n",
       " 6063,\n",
       " 669,\n",
       " 423,\n",
       " 1913,\n",
       " 45576,\n",
       " 25,\n",
       " 484,\n",
       " 2236,\n",
       " 760,\n",
       " 356,\n",
       " 198,\n",
       " 14150,\n",
       " 1913,\n",
       " 5101,\n",
       " 1165,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 49275,\n",
       " 1677,\n",
       " 40,\n",
       " 2937,\n",
       " 25,\n",
       " 198,\n",
       " 5195,\n",
       " 11,\n",
       " 18159,\n",
       " 11,\n",
       " 616,\n",
       " 922,\n",
       " 2460,\n",
       " 11,\n",
       " 6164,\n",
       " 5508,\n",
       " 23788,\n",
       " 11,\n",
       " 198,\n",
       " 8743,\n",
       " 345,\n",
       " 23981,\n",
       " 27012,\n",
       " 30,\n",
       " 198,\n",
       " 198,\n",
       " 5962,\n",
       " 22307,\n",
       " 25,\n",
       " 198,\n",
       " 1135,\n",
       " 2314,\n",
       " 11,\n",
       " 15967,\n",
       " 11,\n",
       " 356,\n",
       " 389,\n",
       " 45171,\n",
       " 1541,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 49275,\n",
       " 1677,\n",
       " 40,\n",
       " 2937,\n",
       " 25,\n",
       " 198,\n",
       " 40,\n",
       " 1560,\n",
       " 345,\n",
       " 11,\n",
       " 2460,\n",
       " 11,\n",
       " 749,\n",
       " 21803,\n",
       " 1337,\n",
       " 198,\n",
       " 11980,\n",
       " 262,\n",
       " 1458,\n",
       " 1173,\n",
       " 1547,\n",
       " 286,\n",
       " 345,\n",
       " 13,\n",
       " 1114,\n",
       " 534,\n",
       " 3382,\n",
       " 11,\n",
       " 198,\n",
       " 7120,\n",
       " 7195,\n",
       " 287,\n",
       " 428,\n",
       " 390,\n",
       " 11999,\n",
       " 11,\n",
       " 345,\n",
       " 743,\n",
       " 355,\n",
       " 880,\n",
       " 198,\n",
       " 31584,\n",
       " 379,\n",
       " 262,\n",
       " 9538,\n",
       " 351,\n",
       " 534,\n",
       " 336,\n",
       " 3080,\n",
       " 355,\n",
       " 10303,\n",
       " 606,\n",
       " 198,\n",
       " 39276,\n",
       " 262,\n",
       " 7993,\n",
       " 1181,\n",
       " 11,\n",
       " 3025,\n",
       " 1781,\n",
       " 481,\n",
       " 319,\n",
       " 198,\n",
       " 464,\n",
       " 835,\n",
       " 340,\n",
       " 2753,\n",
       " 11,\n",
       " 25407,\n",
       " 3478,\n",
       " 7319,\n",
       " 1090,\n",
       " 1443,\n",
       " 198,\n",
       " 5189,\n",
       " 517,\n",
       " 1913,\n",
       " 2792,\n",
       " 355,\n",
       " 4625,\n",
       " 621,\n",
       " 460,\n",
       " 1683,\n",
       " 198,\n",
       " 4677,\n",
       " 451,\n",
       " 287,\n",
       " 534,\n",
       " 26795,\n",
       " 3681,\n",
       " 13,\n",
       " 1114,\n",
       " 262,\n",
       " 390,\n",
       " 11999,\n",
       " 11,\n",
       " 198,\n",
       " 464,\n",
       " 11858,\n",
       " 11,\n",
       " 407,\n",
       " 262,\n",
       " 1458,\n",
       " 1173,\n",
       " 1547,\n",
       " 11,\n",
       " 787,\n",
       " 340,\n",
       " 11,\n",
       " 290,\n",
       " 198,\n",
       " 7120,\n",
       " 14475,\n",
       " 284,\n",
       " 606,\n",
       " 11,\n",
       " 407,\n",
       " 5101,\n",
       " 11,\n",
       " 1276,\n",
       " 1037,\n",
       " 13,\n",
       " 978,\n",
       " 441,\n",
       " 11,\n",
       " 198,\n",
       " 1639,\n",
       " 389,\n",
       " 18665,\n",
       " 416,\n",
       " 35765,\n",
       " 414,\n",
       " 198,\n",
       " 817,\n",
       " 1555,\n",
       " 810,\n",
       " 517,\n",
       " 32743,\n",
       " 345,\n",
       " 11,\n",
       " 290,\n",
       " 345,\n",
       " 47397,\n",
       " 198,\n",
       " 464,\n",
       " 932,\n",
       " 907,\n",
       " 267,\n",
       " 6,\n",
       " 262,\n",
       " 1181,\n",
       " 11,\n",
       " 508,\n",
       " 1337,\n",
       " 329,\n",
       " 345,\n",
       " 588,\n",
       " 17150,\n",
       " 11,\n",
       " 198,\n",
       " 2215,\n",
       " 345,\n",
       " 17328,\n",
       " 606,\n",
       " 355,\n",
       " 5775,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 5962,\n",
       " 22307,\n",
       " 25,\n",
       " 198,\n",
       " 17784,\n",
       " 329,\n",
       " 514,\n",
       " 0,\n",
       " 6407,\n",
       " 11,\n",
       " 5600,\n",
       " 0,\n",
       " 1119,\n",
       " 497,\n",
       " 6,\n",
       " 263,\n",
       " 19951,\n",
       " 329,\n",
       " 514,\n",
       " 198,\n",
       " 25907,\n",
       " 25,\n",
       " 8659,\n",
       " 514,\n",
       " 284,\n",
       " 1145,\n",
       " 680,\n",
       " 11,\n",
       " 290,\n",
       " 511,\n",
       " 3650,\n",
       " 12,\n",
       " 20089,\n",
       " 198,\n",
       " 66,\n",
       " 859,\n",
       " 1150,\n",
       " 351,\n",
       " 13020,\n",
       " 26,\n",
       " 787,\n",
       " 1225,\n",
       " 14137,\n",
       " 329,\n",
       " 514,\n",
       " 1601,\n",
       " 11,\n",
       " 284,\n",
       " 198,\n",
       " 11284,\n",
       " 514,\n",
       " 17496,\n",
       " 26,\n",
       " 14634,\n",
       " 4445,\n",
       " 597,\n",
       " 17950,\n",
       " 462,\n",
       " 719,\n",
       " 198,\n",
       " 27718,\n",
       " 1028,\n",
       " 262,\n",
       " 5527,\n",
       " 11,\n",
       " 290,\n",
       " 2148,\n",
       " 517,\n",
       " 198,\n",
       " 79,\n",
       " 959,\n",
       " 2259,\n",
       " 24895,\n",
       " 4445,\n",
       " 11,\n",
       " 284,\n",
       " 6333,\n",
       " 510,\n",
       " 290,\n",
       " 39300,\n",
       " ...]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "522"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create a sorted list of unique characters in the text\n",
    "chars = sorted(list(set(text_tokens)))\n",
    "vocab_size = len(chars)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First'"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Decode the first token in the text\n",
    "enc.decode([text_tokens[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1393])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = torch.tensor(text_tokens, dtype=torch.long)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "chars = sorted(list(set(text.split(' '))))\n",
    "vocab_size = len(chars)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42197"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"vocab_size\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'banished'?\\n\\nFRIAR\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "chars[100]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1455,   957, 39874, 29614,  5949, 16628, 18572, 24432, 34050, 34057])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Create word-to-index and index-to-word mappings\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "\n",
    "# Functions to encode and decode words\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: \" \".join([itos[x] for x in l])\n",
    "# Encode words using the mappings\n",
    "data = torch.tensor(encode(text.split(' ')), dtype = torch.long)\n",
    "# Display the first 10 tokens in the data\n",
    "data[:10]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'First Citizen:'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Decode the first 10 tokens in the data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m decode(\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[66], line 7\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m      3\u001b[0m itos \u001b[38;5;241m=\u001b[39m {i: ch \u001b[38;5;28;01mfor\u001b[39;00m i, ch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(chars)}\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Functions to encode and decode words\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m encode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m s: [\u001b[43mstoi\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m s]\n\u001b[1;32m      8\u001b[0m decode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m l: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([itos[x] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m l])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Encode words using the mappings\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'First Citizen:'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Decode the first 10 tokens in the data\n",
    "decode(encode(text.split(\"\\n\")[:2]))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134353"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into training and validation sets\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set hyperparameters for the model\n",
    "batch_size = 8\n",
    "block_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 5000\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 32\n",
    "n_embed = 32\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RetNet model\n",
    "model = RetNet(block_size=block_size)\n",
    "# Get a batch of training data\n",
    "xb, yb = get_batch('train', batch_size=batch_size)\n",
    "# Initialize the optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[269], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Forward pass and loss calculation\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m logits, loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m loss\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/miniconda3/envs/retnet_test/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/retnet_test/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[32], line 111\u001b[0m, in \u001b[0;36mRetNet.forward\u001b[0;34m(self, idx, targets)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx, targets\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    110\u001b[0m     B, T \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 111\u001b[0m     token_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_embedding_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     pos_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_table(torch\u001b[38;5;241m.\u001b[39marange(T))\n\u001b[1;32m    113\u001b[0m     x \u001b[38;5;241m=\u001b[39m token_emb \u001b[38;5;241m+\u001b[39m pos_emb\n",
      "File \u001b[0;32m~/miniconda3/envs/retnet_test/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/retnet_test/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/retnet_test/lib/python3.12/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/retnet_test/lib/python3.12/site-packages/torch/nn/functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "\n",
    "# Forward pass and loss calculation\n",
    "logits, loss = model(xb, yb)\n",
    "loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3957,   956,   264, 36543,  1980,  2460,   512,  2822,   810,  7556,\n",
       "           389,   956,    26,  1095,   433,   387],\n",
       "        [  382,  2460,   512, 96945,    11,  6604,   382,  5451, 47317,   512,\n",
       "          2675,   527,   682, 20250,  4856,   311],\n",
       "        [ 9354,   311,   279,  1274,   382,  2460,   512,  1687,  1440,   956,\n",
       "            11,   584,  1440,   956,   382,  5451]])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  280,  3112,   358,   656,  3987,  1695,  2919,   323,  1317,   311,\n",
       "          1518,   382, 58163,    44,  3895,   512,    46, 28146,    11,  1778,\n",
       "           264,  2324,    11,   449,  1778,   264,  7555,    11,  1051, 15234,\n",
       "          4999,  4071],\n",
       "        [46811,    11, 24613,  2277,   757,   198,  1962,   311,  5622,   279,\n",
       "         96923,   382, 16041, 52483,   261,   512, 18293,   279, 38736,   304,\n",
       "         26236,  4059,    11,   323, 48839,  1461,   539,    25,   568,   198,\n",
       "         41450,  1672],\n",
       "        [ 4648,    11,   719,  2547,   596,  9120, 16409,   382,  3442,  6903,\n",
       "           512, 34042,    11,  9120, 16409,     0,   387, 16888,  5092,    11,\n",
       "          2019,   364, 63007, 99419,  2520, 61087, 52677,   810,  8818,   304,\n",
       "           813,  1427]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m xb, yb \u001b[38;5;241m=\u001b[39m get_batch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Forward pass and loss calculation\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m logits, loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/retnet_test/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/retnet_test/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[32], line 111\u001b[0m, in \u001b[0;36mRetNet.forward\u001b[0;34m(self, idx, targets)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx, targets\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    110\u001b[0m     B, T \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 111\u001b[0m     token_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_embedding_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     pos_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_table(torch\u001b[38;5;241m.\u001b[39marange(T))\n\u001b[1;32m    113\u001b[0m     x \u001b[38;5;241m=\u001b[39m token_emb \u001b[38;5;241m+\u001b[39m pos_emb\n",
      "File \u001b[0;32m~/miniconda3/envs/retnet_test/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/retnet_test/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/retnet_test/lib/python3.12/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/retnet_test/lib/python3.12/site-packages/torch/nn/functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get a batch of training data\n",
    "xb, yb = get_batch('train', batch_size=batch_size)\n",
    "\n",
    "\n",
    "# Forward pass and loss calculation\n",
    "logits, loss = model(xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Forward pass and loss calculation\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m logits, loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/retnet_test/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/retnet_test/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[32], line 111\u001b[0m, in \u001b[0;36mRetNet.forward\u001b[0;34m(self, idx, targets)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx, targets\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    110\u001b[0m     B, T \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 111\u001b[0m     token_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_embedding_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     pos_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_table(torch\u001b[38;5;241m.\u001b[39marange(T))\n\u001b[1;32m    113\u001b[0m     x \u001b[38;5;241m=\u001b[39m token_emb \u001b[38;5;241m+\u001b[39m pos_emb\n",
      "File \u001b[0;32m~/miniconda3/envs/retnet_test/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/retnet_test/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/retnet_test/lib/python3.12/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/retnet_test/lib/python3.12/site-packages/torch/nn/functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "\n",
    "# Forward pass and loss calculation\n",
    "logits, loss = model(xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training loop\n",
    "for iter in range(max_iters):\n",
    "    # Every once in a while, evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "\n",
    "    # Sample a batch of data\n",
    "    xb, yb = get_batch('train', batch_size=batch_size)\n",
    "\n",
    "\n",
    "    # Forward pass, loss calculation, backpropagation, and optimization\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate text with different initial contexts\n",
    "context1 = torch.tensor([encode(\"thou art kneel before king\".split(' '))], dtype=torch.long)\n",
    "context2 = torch.tensor([encode(\"Hermione\".split(' '))], dtype=torch.long)\n",
    "context3 = torch.tensor([encode(\"come\".split(' '))], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print generated text using different contexts\n",
    "print(decode(model.generate(context1, max_new_tokes=200)[0].tolist()))\n",
    "print(decode(model.generate(context2, max_new_tokes=200)[0].tolist()))\n",
    "print(decode(model.generate(context3, max_new_tokes=200)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retnet_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
